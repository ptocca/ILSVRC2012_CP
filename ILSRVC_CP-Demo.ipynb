{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.keras.preprocessing import image as keras_image\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions\n",
    "import numpy as np\n",
    "import os\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, clear_output, HTML\n",
    "display(HTML(\"<style>.container { width:90% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "try:\n",
    "    tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "except:\n",
    "    # Invalid device or cannot modify virtual devices once initialized.\n",
    "    print(\"No GPU?\")\n",
    "    clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Setting up pre-trained keras ResNet50 model\")\n",
    "model = ResNet50(weights='imagenet')\n",
    "print(\"Model ready\")\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "if not os.path.exists('val_preds.h5'):\n",
    "    print(\"Downloading MICP calibration data (200MB) - be patient!\")\n",
    "    urllib.request.urlretrieve(\"https://cml.rhul.ac.uk/people/ptocca/ILSVRC2012-CP/val_preds.h5\",\n",
    "                               'val_preds.h5')\n",
    "    clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File('val_preds.h5','r') as f:\n",
    "    preds = f['preds'][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pValues(calibrationAlphas,testAlphas,randomized=False):\n",
    "    testAlphas = np.array(testAlphas)\n",
    "    sortedCalAlphas = np.sort(calibrationAlphas)\n",
    "    \n",
    "    leftPositions = np.searchsorted(sortedCalAlphas,testAlphas)\n",
    "    \n",
    "    if randomized:\n",
    "        rightPositions = np.searchsorted(sortedCalAlphas,testAlphas,side='right')\n",
    "        ties  = rightPositions-leftPositions+1   # ties in cal set plus the test alpha itself\n",
    "        randomizedTies = ties * np.random.uniform(size=len(ties))\n",
    "        return  (len(calibrationAlphas) - rightPositions + randomizedTies)/(len(calibrationAlphas)+1)\n",
    "    else:\n",
    "        return  (len(calibrationAlphas) - leftPositions + 1)/(len(calibrationAlphas)+1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # shape: (num_labels,num_test_objects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def micp_pValues(preds,test_preds,y_cal):\n",
    "    ncm_cal = -preds\n",
    "    ncm_test = -test_preds\n",
    "    \n",
    "    micp_pValues = []\n",
    "\n",
    "    for i in range(test_preds.shape[1]):\n",
    "        p_i = pValues(ncm_cal[:,i][y_cal==i],ncm_test[:,i])\n",
    "        micp_pValues.append(p_i)\n",
    "\n",
    "    micp_pValues = np.array(micp_pValues)\n",
    "    \n",
    "    return micp_pValues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ilsrvc_dir = \"/mnt/d/Research/ILSVRC2012/\"\n",
    "ilsrvc_dir = \".\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_file = os.path.join(ilsrvc_dir,\"ILSVRC2012_validation_ground_truth.txt\")\n",
    "lbls_file = os.path.join(ilsrvc_dir,\"labels.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping_file = os.path.join(ilsrvc_dir,\"ILSVRC2012_mapping.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_to_ki = {}\n",
    "ki_to_synset = {}\n",
    "with open(os.path.join(ilsrvc_dir,'synset_words.txt')) as f:\n",
    "    for i,l in enumerate(f):\n",
    "        n_to_ki[l.split()[0].strip()]=i\n",
    "        ki_to_synset[i]=l[10:].split(\",\")[0].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ii_to_n = [\"Error\"]\n",
    "with open(mapping_file) as f:\n",
    "    for l in f:\n",
    "        lf = l.split()\n",
    "        ii_to_n.append(lf[1].strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ii_to_ki = [0]+[n_to_ki[ii_to_n[i]] for i in range(1,1001)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth_ki = np.zeros(50000,dtype=np.int16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(gt_file) as f:\n",
    "    for i,l in enumerate(f):\n",
    "        ground_truth_ki[i] = ii_to_ki[int(l)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import IntSlider,Image,interactive,VBox,Textarea,Layout,FloatSlider,HBox,Label,Output\n",
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PIL.Image\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mem = joblib.Memory('/dev/shm/joblib',verbose=0)\n",
    "\n",
    "@mem.cache\n",
    "def getImage(url):\n",
    "    img_data = PIL.Image.open(urllib.request.urlopen(url))\n",
    "    if img_data.mode != 'RGB':\n",
    "        img_data = img_data.convert('RGB')\n",
    "    img_data = img_data.resize((224,224))\n",
    "    return img_data    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prob_sets(preds, eps):\n",
    "    preds_as = np.argsort(-preds,axis=1)\n",
    "    preds_cumul = np.cumsum(np.take_along_axis(preds,preds_as,axis=1),axis=1)\n",
    "\n",
    "    set_masks = preds_cumul<1-eps\n",
    "\n",
    "    sets = [(pr_as[m],pr[pr_as[m]]) for pr_as, m,pr in zip(preds_as,set_masks,preds)]\n",
    "    return sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_pic(i,eps):\n",
    "    #img_file = os.path.join(ilsrvc_dir,\"img\",\"ILSVRC2012_val_%08d.JPEG\"%i)\n",
    "    # with open(img_file,\"rb\") as f:\n",
    "    #    img.value = f.read()\n",
    "    url=\"\"\"https://cml.rhul.ac.uk/people/ptocca/ILSVRC2012-CP/img/ILSVRC2012_val_%08d.JPEG\"\"\"%i\n",
    "\n",
    "\n",
    "\n",
    "    # img_data = keras_image.load_img(img_file, target_size=(224, 224))\n",
    "    img_data = getImage(url)\n",
    "    print(\"Image loaded\")\n",
    "    output = io.BytesIO()\n",
    "    img_data.save(output,format=\"PNG\")\n",
    "    img.value = output.getvalue()\n",
    "\n",
    "\n",
    "    # compute ResNet50 preds\n",
    "    x = keras_image.img_to_array(img_data)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    x = preprocess_input(x)\n",
    "    test_preds = model.predict(x)\n",
    "    resNet50_set = zip(*(get_prob_sets(test_preds.reshape(1,-1), eps=eps)[0]))\n",
    "\n",
    "    # compute CP\n",
    "    p_vals = micp_pValues(preds,test_preds,ground_truth_ki)\n",
    "    ps = np.argwhere(p_vals>eps)[:,0].T\n",
    "    ps_p_vals = p_vals[ps].flatten()\n",
    "    sorting_by_p_val = np.argsort(ps_p_vals)[::-1] \n",
    "    ps_synset = [ki_to_synset[k]+\":%0.3f\"%p for k,p in zip(ps[sorting_by_p_val],ps_p_vals[sorting_by_p_val])]\n",
    "    print(ps_synset)\n",
    "    \n",
    "    # Do all widget updates\n",
    "    ## update ground truth widget\n",
    "    lbl = ki_to_synset[ground_truth_ki[i-1]]\n",
    "    desc.children[1].value = lbl\n",
    "\n",
    "    ## update resNet50 widget\n",
    "    resnet50.children[0].value = \"ResNet50 at cumul prob %0.2f\"%(1-eps)\n",
    "    resnet50.children[1].value = \"\\n\".join([\"%s: %0.3f\"%(ki_to_synset[k],pr) for k,pr in resNet50_set])\n",
    "\n",
    "    ## update CP widget\n",
    "    CP.children[0].value = \"Conformal Predictor at significance level %0.2f\"%eps\n",
    "    CP.children[1].value = \"\\n\".join(ps_synset)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "desc = VBox([Label(\"True label\"),\n",
    "             Textarea(\"N/A\",layout=Layout(height=\"100%\"))])\n",
    "\n",
    "img = Image(layout=Layout(height=\"400px\",width=\"400px\"))\n",
    "\n",
    "resnet50 = VBox([Label(\"ResNet50 Probability (top 5)\"),\n",
    "                 Textarea(layout=Layout(height=\"100%\"))])\n",
    "CP = VBox([Label(\"Conformal Predictor at significance level 'eps'\"),\n",
    "           Textarea(layout=Layout(height=\"100%\"))])\n",
    "labels = HBox([desc,resnet50,CP],layout=Layout(height=\"200px\",align_content=\"stretch\"))\n",
    "\n",
    "pic_idx = IntSlider(value=500, min=1,max=2000,continuous_update=False,layout=Layout(width=\"90%\",align_items='center'))\n",
    "eps_slider = FloatSlider(value=0.1,min=0.01,max=1.0,continuous_update=False,step=0.01,layout=Layout(width=\"90%\",align_items='center'))\n",
    "                    \n",
    "\n",
    "gui = VBox([img,pic_idx,eps_slider,labels],layout=Layout(align_items='center'))\n",
    "\n",
    "show_pic(1020,0.1)\n",
    "\n",
    "#clear_output();\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "interactive(show_pic,i = pic_idx, eps = eps_slider)\n",
    "\n",
    "gui"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
